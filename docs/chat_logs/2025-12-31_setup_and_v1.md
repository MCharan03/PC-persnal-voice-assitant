# Chat Log - December 31, 2025

## Session Summary
**User Goal:** Build a personal AI voice assistant for PC (Windows) similar to "Jarvis" or "M.J.", strictly using local-only resources (no third-party cloud APIs).

**Project Name:** Cherry.

## Key Decisions & Architecture
1.  **Privacy First:** All processing must happen locally on the machine.
2.  **Hardware Optimization:** 
    - Leverage User's **NVIDIA RTX 4050 (8GB VRAM)** for AI acceleration.
    - Use **Intel i7-13650HX** for auxiliary processing.
3.  **Tech Stack:**
    - **Language:** Python 3.13.
    - **Wake Word:** `faster-whisper` (tiny model) on GPU buffer.
    - **STT (Ears):** `Faster-Whisper` running on CUDA (float16).
    - **LLM (Brain):** `Ollama` running `Llama 3.2`.
    - **TTS (Voice):** `pyttsx3`.
    - **GUI (Body):** `PyQt6` overlay (Floating Cyan Orb).
    - **VAD:** Energy-based Voice Activity Detection.

## Work Completed
1.  **Environment Setup:**
    - Created Python virtual environment.
    - **Fix:** Downgraded bleeding-edge PyTorch to `2.6.0+cu124` to resolve `cublas64_12.dll` errors with `faster-whisper` / `ctranslate2`.
    - **Fix:** Added DLL directory registration in Python to ensure Windows finds CUDA libraries.
2.  **Module Implementation:**
    - `src/modules/stt.py`: GPU-accelerated transcription.
    - `src/modules/llm.py`: Ollama integration.
    - `src/modules/tts.py`: Audio output.
    - `src/modules/wake_word.py`: Keyword spotting.
    - `src/modules/actions.py`: System automation.
3.  **Core Logic (`src/main.py`):**
    - **Refactor:** Moved audio processing out of the `sounddevice` callback into a thread-safe `queue`. This resolved application freezing/blocking issues.
    - Added visual debug volume meter to console.
4.  **UI Implementation (`src/gui.py`):**
    - Transparent overlay window with pulsing animation.

## Troubleshooting Session 2 (EOD)
- **Issue:** `RuntimeError: Library cublas64_12.dll is not found`
    - **Resolution:** Reinstalled PyTorch with CUDA 12.4 support (`pip install torch ... --index-url .../cu124`) and manually added the library path in code.
- **Issue:** Application "Not Listening" / Freezing.
    - **Resolution:** Refactored `main.py` to use a Producer-Consumer pattern with a `queue.Queue` so the audio callback is never blocked by heavy AI inference.
- **Current Issue:** Microphone Input Silence.
    - The application runs and connects to the GPU.
    - Input device is detected: `Microphone Array (IntelÂ® Smart Sound Technology)`.
    - However, the RMS (volume) level remains at `0.0000` or extremely low, failing to trigger the Wake Word or VAD.

## Next Steps (Next Year)
- [ ] Debug Microphone Input:
    - Check Windows Privacy settings (Microphone access for Python).
    - Test alternate audio backends (WASAPI/MME).
    - Adjust Input Gain.
- [ ] Train/Find a custom "Hey Cherry" wake word model (currently checking via STT).
- [ ] Upgrade TTS to `Kokoro-82M`.